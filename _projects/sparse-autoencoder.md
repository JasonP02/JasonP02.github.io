---
layout: project
title: "Sparse Autoencoder Investigations"
subtitle: "Exploring neural network interpretability"
date: "January 2024 - Present"
status: "ongoing"
domain: machine-learning
image: "/assets/images/SAE.jpg"
has_github: true
github: "https://github.com/jasonp02/sae-investigations"
---

## Overview
Research project focused on understanding and implementing sparse autoencoders
for neural network interpretability. This is an ongong project with a lot of unresolved details. Currently investigating how a pretrained SAE can investigate the chain of thought reasoning for models like OpenAI o1.

## Technical Details
• Implementation of sparse autoencoder architectures
• Training pipeline development
• Cloud computing integration
• Performance optimization

<div class="tech-stack">
  <span class="tech-tag">Python</span>
  <span class="tech-tag">PyTorch</span>
  <span class="tech-tag">Cloud Computing</span>
  <span class="tech-tag">Machine Learning</span>
</div>

## Key Learnings
• Advanced ML concepts
• Cloud resource management
• Optimization techniques
• Research methodologies

## Challenges & Solutions
The main challenge so far has been setting up efficient development environments and managing
computational resources. Currently looking into training a SAE using vast.ai cloud compute.
